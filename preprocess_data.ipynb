{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Large Dataset in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling large dataset with keras by overriding the datagenerator class\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will first read all the images and save them in .npy file for each image individually and also two different mapping file for their labels for train data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '2', '4', '1', '6', '9', '0', '5', '8']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"./data/trainingSet\"\n",
    "data_dirs = os.listdir(data_path)\n",
    "data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_npy_data(img_path, save_path):\n",
    "    im = Image.open(img_path)\n",
    "    im2arr = np.array(im, dtype = np.float32) # im2arr.shape: height x width x channel\n",
    "    #arr2im = Image.fromarray(im2arr)\n",
    "    #print(im2arr.shape)\n",
    "    img_data = im2arr / 255.0\n",
    "    #print(img_data)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        np.save(f, img_data, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3045.7000000000003\n",
      "3080.7000000000003\n",
      "2923.9\n",
      "2850.4\n",
      "3278.7999999999997\n",
      "2895.9\n",
      "2931.6\n",
      "2892.4\n",
      "2656.5\n",
      "2844.1\n"
     ]
    }
   ],
   "source": [
    "train_data = \"\"\n",
    "val_data = \"\"\n",
    "\n",
    "percentange_of_train_data = 7 #7 means 70 percent\n",
    "\n",
    "for d in data_dirs:\n",
    "    img_path = data_path + \"/\" + d\n",
    "    images = os.listdir(img_path)\n",
    "    num_of_images = len(images)\n",
    "    train_sample = (num_of_images / 10) * percentange_of_train_data\n",
    "    print(train_sample)\n",
    "    img_name_counter = 0\n",
    "    \n",
    "    for image in images:\n",
    "        img = img_path + \"/\" + image\n",
    "        npy_file = str(d) + \"_\" + str(img_name_counter) + \".npy\"\n",
    "        save_path = \"./npy/\" + npy_file\n",
    "        save_npy_data(img, save_path)\n",
    "        img_name_counter += 1\n",
    "        if(img_name_counter > train_sample):\n",
    "            val_data += npy_file + \",\" + d + \"\\n\"\n",
    "        else:\n",
    "            train_data += npy_file + \",\" + d + \"\\n\"\n",
    "with open(\"train_data.csv\",\"w\") as tf:\n",
    "    tf.write(train_data)\n",
    "with open(\"val_data.csv\",\"w\") as vf:\n",
    "    vf.write(val_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
